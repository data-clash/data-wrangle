{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling Report \n",
    "\n",
    "##### Goal: Wrangle WeRateDogs Twitter data to create interesting and trustworthy analyses and visualizations. \n",
    "\n",
    "## 1. Gathering Data\n",
    "\n",
    "Three data sources were used for this report:\n",
    "##### 1. Twitter Archive Enhanced \n",
    "Twitter Archive Enhanced was provided in a csv format. This was uploaded manually on the server and loaded in a twitter dataframe. This file contained the main structure information for this analysis.\n",
    "\n",
    "##### 2. Tweet Information \n",
    "As twitter account was not approved for almost a week, I used the pre-complied json file for analysis (tweet-json.json). I manually uploaded this file on the server and loaded the data on df_tweet dataframe. \n",
    "\n",
    "##### 3. Image Prediction \n",
    "Image prediction file was fetched from the internet based on the url provided. Values in this file were tab seperated. this file was read in a pred data frame. \n",
    "\n",
    "## 2.Assess Data: Visually and Programmatically\n",
    "\n",
    "#### Visual assessment of Data \n",
    "1. It was clear from the three data sets, that twitter archice will be main data structure to which tweet information and image prediction results will be comined into. \n",
    "2. Many unwanted columns were seen which would not help in assessment due to missing values. E.g (retweeted_status_timestamp_* ,in_reply_*)\n",
    "3. Image prediction data and tweet json data were clean and did not require any additional cleaning effort than merging them with the twitter archive data. \n",
    "4. I looked closely on why some of the rating_denominators were not 10, it seemed like due to two fraction values in the text, the parsing algorithm wrongly parsed different ratios as rating value. This requires an update on parsing of text. \n",
    "5. When I looked at expanded_urls, I found these urls contain no useful information but just tweet_id. So this was a redundant column. \n",
    "6. Text column contained text and image url. \n",
    "7. I observed when 'very' appears as a dog name, it was a reply from the WeRateOnlyDogs owner that they accept only dog names. \n",
    "\n",
    "#### Programmatic Assesment of Data \n",
    "I used panda functions such as : describe, info, value_counts(), isnull(),.duplicated(),head(),tail(),query() to assess data \n",
    "\n",
    "1. I checked if there were any duplicated tweet ids.  \n",
    "2. The mininum value for numerator and denominator is 0, which looked quite odd, as for denominator should always be 10 and people would not put a 0 rating on their dog. \n",
    "3. I also observed for rating numerator less than 5, wrongly extracted values were parsed. \n",
    "4. There was a lot of wrongly extracted dog names. They were all easy to detect with lower case letter. \n",
    "5. There were multiple stages per tweet or missing stages. \n",
    "\n",
    "##### Quality:\n",
    "1. Missing values for 6 columns \n",
    "    a. in_reply_to_status_id \n",
    "    b. in_reply_to_user_id \n",
    "    c. expanded_urls etc\n",
    "    d. retweeted_status_id \n",
    "    e. retweeted_status_user_id\n",
    "    f. retweeted_status_timestamp\n",
    "2. source column has HTML markup tags along with url. we need the value for this column. e.g Twitter for iPhone  \n",
    "3. timestamp column can be reformatted to YYYY-MM-dd hh:mm:ss format and we do not need addtional milli-seconds after seconds\n",
    "4. name values for dogs contain incorrect in many rows. This is extracted from the text field. But due to unstructured texts or missing names in some instances, the correct names are not extracted for all dogs. E.g acutally, unacceptable,etc. Most of these terms can be has first letter in lower-case\n",
    "5. names with 'very' are wrong images which are not related to dogs and should be removed. \n",
    "6. It is observered that when phrase 'We only rate dogs' appears in text, the tweet entries are invalid. Such also in the case of tweet of index id 1527\n",
    "7. text coulmn with no image url should be filtered out. As they could be retweets\n",
    "8. rating_denominator cannot be more than 10. For ids a to f, the numerators where not correctly extracted. \n",
    "    <br> a. For id 313 -->  Correct values to numerator 13, denominator 10 \n",
    "    <br> b. For id 784 -->  Correct values to numerator 14, denominator 10\n",
    "    <br> c. For id 1068 --> Correct values to numerator 14, denominator 10\n",
    "    <br> d. For id 1202 --> Correct values to numerator 11, denominator 10\n",
    "    <br> e. For id 1662 --> Correct values to numerator 10, denominator 10\n",
    "    <br> f. For id 2335 --> Correct values to numerator 9, denominator 10\n",
    "    <br> g. Remove other ids where denominator is not equal to 10\n",
    "9. rating_numerator check  : 2 ids where numerator = 0\n",
    "10. stage column \n",
    "    <br> a. stage for id 191 should be set to puppo \n",
    "    <br> b. stage for id 200 should be set to floofer\n",
    "    <br> c. There are stages with multiple values, concatenate them\n",
    "11. Expanded_urls column contains redundant information as tweet_id.\n",
    "12. Remove rows where retweeted_status_id is present as it indicates retweets and not actual tweets\n",
    "\n",
    "##### Tidyness:\n",
    "1. Merge columns doggo, floofer, pupper, puppo values into one new column 'stage'\n",
    "2. text coulmn has image url of the tweet which should be a seperate column other than text. \n",
    "3. join table df_tweet with df_twitter with columns retweet_count and favorite_count\n",
    "\n",
    "\n",
    "## 3.Cleaning Data\n",
    "I first created a copy of twitter dataframe to df_twitter. This was quite useful to retrace steps without losing actual data. \n",
    "I followed the following steps in cleaning data:\n",
    "1. Dropped unwanted columns with drop() function on df_twitter data\n",
    "2. Removed retweets from the data set\n",
    "3. Created a new column stage and merged the dog stage column information to generate dog stage and dropped the additional columns on dog stages \n",
    "4. I concatenated dog stages where multiple dog stages were set. \n",
    "5. I used image predictions data frame to predict dog breeds on prediction p1 with confidence level greater than 95% and dog option was True. p2 and p3 predictions did not have more than 95% confidence so there was no point in assessing these two options. \n",
    "6. Whereever possible I set the null values to NA using fillna, so that we do not have multiple types of null values\n",
    "7. html tages from source value was cleaned using REGEX replace\n",
    "8. Left Joined archive file with tweet_json on tweet_id with fields jpg_url, tweet_count and favorite_count. \n",
    "9. timestamp field datatype was set to datetime and format was changed to  YYYY-MM-dd hh:mm:ss\n",
    "10. I found names with lower first letter and checked for names in text, if not found replace it with NA. I observed most of the texts which had tweet names, these names were preceeded with texts 'This is', 'That is', 'named','name is' and the name always started with capital letter. \n",
    "11. Image url from text was seperated into a new column. And url was removed from text. \n",
    "12. Numerator and denomintor values were partially cleaned manually and programmatically.\n",
    "\n",
    "After each coding step, I tested the results with assert, describe,info or head functions. \n",
    "\n",
    "## 4.Storing Data \n",
    "Data was stored in a csv file named twitter_archive_master.csv with no index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
